{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-Based Reinforcement Learning\n",
    "\n",
    "In this notebook, we implement a set-based reinforcement learning algorithm, which is based on the paper [Training Verifiably Robust Agents using Set-Based Reinforcement Learning](https://arxiv.org/abs/2408.09112). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manuel/ETH_Code/SemProj/SetBasedRL/.venv/lib/python3.12/site-packages/torch/cuda/__init__.py:129: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from SBML import ZonoTorch as zt\n",
    "from SBML import SBRL as sbrl\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "seed = torch.random.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "System dynamics of 1d Quadrotor:\n",
    "$$\\begin{bmatrix}\\dot z\\\\ \\ddot z\\end{bmatrix} = \\begin{bmatrix}\\dot z\\\\ (u+1)/(2*m)-g\\end{bmatrix}$$\n",
    "Reward function: \n",
    "$$r = -|z| - 0.1*|\\dot z|$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 0.05\n",
    "g = 9.81\n",
    "\n",
    "def dynamics(x,u):\n",
    "    dx = torch.tensor([[x[0,1],(u[0,0]+1)/(2*m)-g]]).to(device=DEVICE)\n",
    "    return dx\n",
    "\n",
    "def reward(x,u,x_next):\n",
    "    r = - torch.sum(torch.abs(x*torch.tensor([[1,0.1]]).to(device=DEVICE)))\n",
    "    return r\n",
    "\n",
    "init_state = zt.set.Interval(torch.tensor([[-4,4],[0,0]]).to(device=DEVICE))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actor and Critic models are implemented using PyTorch. The actor and critic are simple feedforward neural networks with 2 hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor = torch.nn.Sequential(\n",
    "    torch.nn.Linear(2, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 32),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(32, 1),\n",
    "    torch.nn.Tanh()\n",
    ")\n",
    "\n",
    "critic = torch.nn.Sequential(\n",
    "    torch.nn.Linear(3, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 32),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(32, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_options = {\n",
    "    'ct': 0.1,\n",
    "    'dt': 0.01,\n",
    "    'max_step': 30,\n",
    "    'initial_ops': 'uniform',\n",
    "}\n",
    "\n",
    "senv = sbrl.SetEnvironmnent(init_state,env_options,dynamics,reward,device=DEVICE)\n",
    "\n",
    "ddpg_ops = {\n",
    "    'actor_lr': 1e-4,\n",
    "    'actor_train_mode': 'set',\n",
    "    'critic_lr': 1e-3,\n",
    "    'critic_train_mode': 'set',\n",
    "    'gamma': 0.99,\n",
    "    'tau': 0.005,\n",
    "    'buffer_size': 10000,\n",
    "    'batch_size': 64,\n",
    "    'exp_noise': 0.2,\n",
    "    'action_ub': 1,\n",
    "    'action_lb': -1,\n",
    "    'noise': .1,\n",
    "    'actor_eta': 0.01,\n",
    "}\n",
    "agent = sbrl.DDPG(actor,critic,ddpg_ops,DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reinforcment Learning Parameters:\n",
      "=================================\n",
      "Standard-RL Options:\n",
      "--------------------\n",
      "Discount Factor (gamma): 0.99\n",
      "Buffer Size: 10000\n",
      "Batch Size: 64\n",
      "Episodes: 1000\n",
      "Device: cpu\n",
      "\n",
      "Actor Options:\n",
      "--------------\n",
      "Learning Rate: 0.0001\n",
      "Training Mode: set\n",
      "Eta: 0.01\n",
      "Omega: 0.5\n",
      "Noise: 0.1\n",
      "\n",
      "Critic Options:\n",
      "---------------\n",
      "Learning Rate: 0.001\n",
      "Training Mode: set\n",
      "Eta: 0.01\n",
      "=================================\n",
      "\n",
      "\n",
      "Training Information:\n",
      "=====================\n",
      "|Episode\t|Elapsed Time\t|Reward\t|Q-Value\t|Critic-Loss\t|Actor-Loss\n",
      "|-------\t|----------\t|----------\t|-----------\t|-----------\t|----------\n",
      "|0\t|1.2911546230316162\t|-365.95947265625\t|-0.11112702637910843\t|1.1340760922431945\t|0.4561907829344273\n",
      "|1\t|4.103039741516113\t|-331.2398986816406\t|-2.3122174739837646\t|0.340932719707489\t|4.110089967250824\n",
      "|2\t|6.805701017379761\t|-296.4527893066406\t|-0.31406527757644653\t|0.3338134071230888\t|5.251364207267761\n",
      "|3\t|9.638569355010986\t|-190.66384887695312\t|-2.3686912059783936\t|0.41944458842277527\t|6.440931539535523\n",
      "|4\t|12.279626369476318\t|-423.9900817871094\t|-2.1137397289276123\t|0.4958591279387474\t|7.309592809677124\n",
      "|5\t|15.171218633651733\t|-248.39132690429688\t|-9.712603569030762\t|0.6046691709756851\t|8.732059636116027\n",
      "|6\t|17.85582423210144\t|-396.5919494628906\t|-6.173925399780273\t|0.7913368651270867\t|10.062822542190553\n",
      "|7\t|20.76208782196045\t|-406.82061767578125\t|-3.4233314990997314\t|1.0116577821969985\t|11.701751766204834\n",
      "|8\t|24.14998459815979\t|-227.4466552734375\t|-2.141469955444336\t|1.2458927229046821\t|13.056778869628907\n",
      "|9\t|27.50178813934326\t|-435.5641174316406\t|-11.48250675201416\t|1.6359255793690681\t|14.230118436813354\n",
      "|10\t|30.943705558776855\t|-309.442626953125\t|-4.749887466430664\t|1.4687637981772423\t|15.699579038619994\n",
      "|11\t|34.46529817581177\t|-167.8854217529297\t|-5.002641677856445\t|1.4863953378796577\t|17.21276728630066\n",
      "|12\t|37.98240566253662\t|-382.871337890625\t|-14.979000091552734\t|2.402067039906979\t|18.120015926361084\n",
      "|13\t|41.27407431602478\t|-567.9287719726562\t|-4.043486595153809\t|2.826413234770298\t|20.23927095413208\n",
      "|14\t|45.12845993041992\t|-499.3070983886719\t|-17.455263137817383\t|2.485722306072712\t|22.61552267074585\n",
      "|15\t|48.39374351501465\t|-385.3526306152344\t|-15.254021644592285\t|2.849108283817768\t|24.225697212219238\n",
      "|16\t|51.999425411224365\t|-233.3756866455078\t|-6.5528669357299805\t|3.1858825886249544\t|25.63544616699219\n",
      "|17\t|55.61793255805969\t|-399.4805908203125\t|-20.69562339782715\t|3.980217997431755\t|27.036189002990724\n",
      "|18\t|59.090439319610596\t|-370.5616149902344\t|-17.209671020507812\t|5.590946572422982\t|28.32477294921875\n",
      "|19\t|62.35645389556885\t|-395.0601501464844\t|-12.270062446594238\t|4.0485378241539\t|29.788920707702637\n",
      "|20\t|65.94237518310547\t|-484.452880859375\t|-4.493582725524902\t|4.541711968183518\t|32.14236961364746\n",
      "|21\t|69.61884999275208\t|-382.7048034667969\t|-12.906052589416504\t|4.80410226225853\t|33.65687604904175\n",
      "|22\t|72.82533025741577\t|-962.8468627929688\t|-34.534542083740234\t|7.8781937313079835\t|34.78438245773315\n",
      "|23\t|76.30239295959473\t|-173.63275146484375\t|-7.536701679229736\t|8.652040836215019\t|37.4500449180603\n",
      "|24\t|79.9418215751648\t|-335.9307556152344\t|-17.460670471191406\t|11.17616696536541\t|38.29122699737549\n",
      "|25\t|83.46582198143005\t|-608.9840698242188\t|-36.6373291015625\t|10.049295039772987\t|40.00688049316406\n",
      "|26\t|86.72508335113525\t|-405.0652770996094\t|-7.174118518829346\t|16.182313002943992\t|42.34158550262451\n",
      "|27\t|90.03830885887146\t|-463.2745361328125\t|-38.24836349487305\t|14.228719022870063\t|44.245286293029785\n",
      "|28\t|93.35486149787903\t|-541.26708984375\t|-33.863868713378906\t|11.727835857868195\t|45.90515140533447\n",
      "|29\t|96.7970118522644\t|-315.9375305175781\t|-42.467384338378906\t|21.578561262488364\t|46.78544784545898\n",
      "|30\t|100.30808091163635\t|-249.30886840820312\t|-29.42580223083496\t|12.769869782924651\t|48.288723907470704\n",
      "|31\t|103.87927651405334\t|-407.0569763183594\t|-7.183313369750977\t|24.34720825910568\t|49.896881103515625\n",
      "|32\t|107.37620902061462\t|-268.584228515625\t|-20.220359802246094\t|28.81397916197777\t|50.61720600128174\n",
      "|33\t|110.69888091087341\t|-979.7498779296875\t|-49.73231506347656\t|18.417528402805328\t|52.11864570617676\n",
      "|34\t|114.40942311286926\t|-349.4040222167969\t|-18.55113410949707\t|26.43465466439724\t|55.19936367034912\n",
      "|35\t|117.92396545410156\t|-307.9640197753906\t|-11.149672508239746\t|41.411901843547824\t|55.71951026916504\n",
      "|36\t|121.26698422431946\t|-411.59765625\t|-13.71834945678711\t|27.189961408376693\t|57.42232524871826\n",
      "|37\t|124.5205397605896\t|-279.9642639160156\t|-7.8267669677734375\t|29.996087017059327\t|57.97994255065918\n",
      "|38\t|127.96716570854187\t|-260.0999755859375\t|-15.70042896270752\t|45.678692605495456\t|59.4052857208252\n",
      "|39\t|131.35665011405945\t|-770.0560302734375\t|-47.59387969970703\t|22.466421777606012\t|61.52777530670166\n",
      "|40\t|134.7040569782257\t|-430.2838134765625\t|-53.72918701171875\t|53.003312346935274\t|62.2727547454834\n",
      "|41\t|138.15653944015503\t|-330.8741760253906\t|-27.20321273803711\t|30.30251936852932\t|65.43130695343018\n",
      "|42\t|141.1393609046936\t|-321.8630676269531\t|-17.081783294677734\t|58.354562584161755\t|65.7163660812378\n",
      "|43\t|144.31182765960693\t|-286.1906433105469\t|-50.73640060424805\t|46.531550487279894\t|65.13744598388672\n",
      "|44\t|147.50704193115234\t|-568.9837036132812\t|-56.78098678588867\t|51.01534430265426\t|66.87826751708984\n",
      "|45\t|151.084734916687\t|-349.4244079589844\t|-50.84884262084961\t|48.93466613054275\t|68.53292057037353\n",
      "|46\t|154.40740180015564\t|-707.0833740234375\t|-38.179786682128906\t|38.225717599391935\t|70.04771148681641\n",
      "|47\t|157.4603407382965\t|-380.7554931640625\t|-32.8079833984375\t|48.28572001695633\t|71.88070007324218\n",
      "|48\t|160.82255387306213\t|-418.775390625\t|-64.31741333007812\t|38.036785422563554\t|73.6284635925293\n",
      "|49\t|164.42192673683167\t|-251.73739624023438\t|-30.025758743286133\t|87.67916196107865\t|73.94746768951416\n",
      "|50\t|167.93662071228027\t|-329.9358215332031\t|-32.92586898803711\t|67.67562093853951\t|72.81309673309326\n",
      "|51\t|171.28847551345825\t|-475.91259765625\t|-54.64612579345703\t|39.301909610033036\t|75.13524234771728\n",
      "|52\t|174.85827136039734\t|-533.909423828125\t|-23.178234100341797\t|57.312374227046966\t|76.65091079711914\n",
      "|53\t|178.34855031967163\t|-454.2181701660156\t|-22.104738235473633\t|54.50234989404678\t|77.16991828918457\n",
      "|54\t|182.00983381271362\t|-338.33056640625\t|-59.775299072265625\t|92.08664713978767\t|79.27074394226074\n",
      "|55\t|185.49754285812378\t|-340.0950012207031\t|-44.04859924316406\t|65.01256710767746\t|79.5410990524292\n",
      "|56\t|189.2234115600586\t|-286.469970703125\t|-30.595565795898438\t|67.20745259404183\t|80.86711837768554\n",
      "|57\t|192.76971125602722\t|-324.7203063964844\t|-54.394248962402344\t|38.03370818853378\t|82.80347640991211\n",
      "|58\t|196.2102406024933\t|-533.452392578125\t|-30.307228088378906\t|52.904510366916654\t|82.14114387512207\n",
      "|59\t|199.62604403495789\t|-265.75958251953125\t|-35.847198486328125\t|73.21877351164818\t|83.23616500854492\n",
      "|60\t|203.15946745872498\t|-231.6259765625\t|-60.29990005493164\t|76.89897315621376\t|84.94875389099121\n",
      "|61\t|206.94361805915833\t|-322.5555114746094\t|-29.388185501098633\t|107.0407945728302\t|84.19360321044923\n",
      "|62\t|210.29481053352356\t|-483.8757019042969\t|-57.718299865722656\t|34.92425017476082\t|84.99692543029785\n",
      "|63\t|213.88036036491394\t|-307.5537414550781\t|-36.48925018310547\t|58.808019750118255\t|87.20127029418946\n",
      "|64\t|217.5662305355072\t|-460.4680480957031\t|-65.7654037475586\t|73.97830644011498\t|86.0495580291748\n",
      "|65\t|221.43197226524353\t|-431.8207702636719\t|-62.50095748901367\t|34.80304157495499\t|88.55725952148437\n",
      "|66\t|224.75529766082764\t|-165.37765502929688\t|-50.41697692871094\t|90.15918335556984\t|89.0957706451416\n",
      "|67\t|228.49737358093262\t|-645.0411376953125\t|-44.38529586791992\t|60.89392059803009\t|89.34228881835938\n",
      "|68\t|232.01592922210693\t|-319.64886474609375\t|-47.369384765625\t|90.93176249980927\t|89.92060539245605\n",
      "|69\t|235.15197706222534\t|-355.74359130859375\t|-29.445117950439453\t|111.28677213788032\t|91.65422584533691\n",
      "|70\t|238.75666570663452\t|-210.446044921875\t|-32.55425262451172\t|80.090850481987\t|91.43198867797851\n",
      "|71\t|242.21710062026978\t|-274.5369567871094\t|-61.06544876098633\t|100.6599235779047\t|92.54370773315429\n",
      "|72\t|245.8695924282074\t|-593.8455810546875\t|-72.03852844238281\t|96.00432733416557\t|93.39352096557617\n",
      "|73\t|249.73078203201294\t|-449.1230163574219\t|-81.02413177490234\t|94.17448462486267\t|95.28852508544922\n",
      "|74\t|253.5056071281433\t|-439.4588623046875\t|-59.20929718017578\t|141.1518723130226\t|95.96115531921387\n",
      "|75\t|256.98067450523376\t|-321.8124694824219\t|-75.01715087890625\t|85.901749355793\t|96.24889480590821\n",
      "|76\t|260.5112838745117\t|-347.2341613769531\t|-78.16187286376953\t|102.6958561372757\t|96.26194374084473\n",
      "|77\t|264.0716595649719\t|-424.8852233886719\t|-75.27957916259766\t|85.97937178373337\t|97.42499519348145\n",
      "|78\t|267.6088583469391\t|-369.6175842285156\t|-48.20297622680664\t|73.98909625530243\t|97.73931228637696\n",
      "|79\t|271.38032627105713\t|-405.2562561035156\t|-60.582489013671875\t|69.21392705321313\t|98.46553802490234\n",
      "|80\t|274.9746537208557\t|-227.1537322998047\t|-49.673545837402344\t|105.75720268249512\t|99.72495903015137\n",
      "|81\t|278.6540789604187\t|-359.5970764160156\t|-50.89699172973633\t|96.34764629244805\t|100.22391059875488\n",
      "|82\t|282.2342526912689\t|-233.8123016357422\t|-63.70065689086914\t|151.99605729579926\t|99.68049583435058\n",
      "|83\t|285.86369228363037\t|-302.4178466796875\t|-63.2002067565918\t|95.90337725996972\t|99.98136344909668\n",
      "|84\t|289.26140832901\t|-353.1285705566406\t|-79.839599609375\t|61.447898082733154\t|101.20940452575684\n",
      "|85\t|292.83042788505554\t|-480.39068603515625\t|-70.4707260131836\t|93.19035276055337\t|101.67476837158203\n",
      "|86\t|296.3176078796387\t|-345.3031311035156\t|-60.9401969909668\t|122.28513499379159\t|102.43942657470703\n",
      "|87\t|300.09277510643005\t|-210.737060546875\t|-67.25129699707031\t|71.06372853755951\t|101.84973686218262\n",
      "|88\t|304.05357670783997\t|-492.69573974609375\t|-70.76679992675781\t|114.61842009425163\t|101.61261444091797\n",
      "|89\t|307.924964427948\t|-303.616455078125\t|-72.08098602294922\t|132.6892332792282\t|103.51162734985351\n",
      "|90\t|311.6201374530792\t|-510.1680908203125\t|-66.07322692871094\t|57.00338852405548\t|103.68315719604492\n",
      "|91\t|315.2542760372162\t|-450.7752990722656\t|-61.59052276611328\t|147.30819315075874\t|103.44609985351562\n",
      "|92\t|318.6847264766693\t|-252.81040954589844\t|-57.809326171875\t|156.6963000035286\t|105.4808480834961\n",
      "|93\t|322.3639757633209\t|-339.60498046875\t|-53.633750915527344\t|108.19844960331916\t|104.74222557067871\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43msenv\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ETH_Code/SemProj/SetBasedRL/examples/../SBML/SBRL/actorcitic.py:102\u001b[0m, in \u001b[0;36mActorCritic.train\u001b[0;34m(self, env, episodes, verbose)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_step \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    100\u001b[0m     q_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval(state,a)\n\u001b[0;32m--> 102\u001b[0m next_state, reward, done, _ \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(action, Zonotope):\n\u001b[1;32m    104\u001b[0m     action \u001b[38;5;241m=\u001b[39m action\u001b[38;5;241m.\u001b[39m_tensor\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_dim,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/ETH_Code/SemProj/SetBasedRL/examples/../SBML/SBRL/senv.py:75\u001b[0m, in \u001b[0;36mSetEnvironmnent.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misDone \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(action,torch\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstepNum \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 75\u001b[0m next_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_dynamics\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mct\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrewardfun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate,action,next_state)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m next_state\n",
      "File \u001b[0;32m~/ETH_Code/SemProj/SetBasedRL/examples/../SBML/SBRL/senv.py:92\u001b[0m, in \u001b[0;36mSetEnvironmnent.step_dynamics\u001b[0;34m(self, state, action, ct, dt)\u001b[0m\n\u001b[1;32m     90\u001b[0m interm_state \u001b[38;5;241m=\u001b[39m state\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_steps):\n\u001b[0;32m---> 92\u001b[0m     interm_state \u001b[38;5;241m=\u001b[39m interm_state \u001b[38;5;241m+\u001b[39m dtt\u001b[38;5;241m*\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdynamic\u001b[49m\u001b[43m(\u001b[49m\u001b[43minterm_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m interm_state\n",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m, in \u001b[0;36mdynamics\u001b[0;34m(x, u)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdynamics\u001b[39m(x,u):\n\u001b[0;32m----> 5\u001b[0m     dx \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mg\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mDEVICE)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dx\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "agent.train(senv,1000,True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
