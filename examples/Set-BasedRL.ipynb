{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-Based Reinforcement Learning\n",
    "\n",
    "In this notebook, we implement a set-based reinforcement learning algorithm, which is based on the paper [Training Verifiably Robust Agents using Set-Based Reinforcement Learning](https://arxiv.org/abs/2408.09112). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from SBML import ZonoTorch as zt\n",
    "from SBML import SBRL as sbrl\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "seed = torch.random.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "System dynamics of 1d Quadrotor:\n",
    "$$\\begin{bmatrix}\\dot z\\\\ \\ddot z\\end{bmatrix} = \\begin{bmatrix}\\dot z\\\\ (u+1)/(2*m)-g\\end{bmatrix}$$\n",
    "Reward function: \n",
    "$$r = -|z| - 0.1*|\\dot z|$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 0.05\n",
    "g = 9.81\n",
    "\n",
    "def dynamics(x,u):\n",
    "    dx = torch.tensor([[x[0,1],(u[0,0]+1)/(2*m)-g]]).to(device=DEVICE)\n",
    "    return dx\n",
    "\n",
    "def reward(x,u,x_next):\n",
    "    r = - torch.sum(torch.abs(x*torch.tensor([[1,0.1]]).to(device=DEVICE)))\n",
    "    return r\n",
    "\n",
    "init_state = zt.set.Interval(torch.tensor([[-4,4],[0,0]]).to(device=DEVICE))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actor and Critic models are implemented using PyTorch. The actor and critic are simple feedforward neural networks with 2 hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor = torch.nn.Sequential(\n",
    "    torch.nn.Linear(2, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 32),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(32, 1),\n",
    "    torch.nn.Tanh()\n",
    ")\n",
    "\n",
    "critic = torch.nn.Sequential(\n",
    "    torch.nn.Linear(3, 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 32),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(32, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_options = {\n",
    "    'ct': 0.1,\n",
    "    'dt': 0.01,\n",
    "    'max_step': 30,\n",
    "    'initial_ops': 'uniform',\n",
    "}\n",
    "\n",
    "senv = sbrl.SetEnvironmnent(init_state,env_options,dynamics,reward,device=DEVICE)\n",
    "\n",
    "ddpg_ops = {\n",
    "    'actor_lr': 0.001,\n",
    "    'actor_train_mode': 'set',\n",
    "    'critic_lr': 0.01,\n",
    "    'critic_train_mode': 'point',\n",
    "    'gamma': 0.99,\n",
    "    'tau': 0.005,\n",
    "    'buffer_size': 1000,\n",
    "    'batch_size': 64,\n",
    "    'exp_noise': 0.1,\n",
    "    'action_ub': 1,\n",
    "    'action_lb': -1,\n",
    "    'noise': .1,\n",
    "    'actor_eta': 0.1,\n",
    "}\n",
    "agent = sbrl.DDPG(actor,critic,ddpg_ops,DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reinforcment Learning Parameters:\n",
      "=================================\n",
      "Standard-RL Options:\n",
      "--------------------\n",
      "Discount Factor (gamma): 0.99\n",
      "Buffer Size: 1000\n",
      "Batch Size: 64\n",
      "Episodes: 1000\n",
      "Device: cuda\n",
      "\n",
      "Actor Options:\n",
      "--------------\n",
      "Learning Rate: 0.001\n",
      "Training Mode: set\n",
      "Eta: 0.1\n",
      "Omega: 0.5\n",
      "Noise: 0.1\n",
      "\n",
      "Critic Options:\n",
      "---------------\n",
      "Learning Rate: 0.01\n",
      "Training Mode: point\n",
      "=================================\n",
      "\n",
      "\n",
      "Training Information:\n",
      "=====================\n",
      "|Episode\t|Elapsed Time\t|Reward\t|Q-Value\t|Critic-Loss\t|Actor-Loss\n",
      "|-------\t|----------\t|----------\t|-----------\t|-----------\t|----------\n",
      "|0\t|0.5267963409423828\t|-764.5018310546875\t|-0.10723283886909485\t|0.4083968749456108\t|1.190430383682251\n",
      "|1\t|1.1507568359375\t|-5759.32861328125\t|-2.880527973175049\t|3.59861093390733\t|13.428755819797516\n",
      "|2\t|1.7643051147460938\t|-1703.07568359375\t|-5.702415466308594\t|51.47426887273789\t|32.837101516723635\n",
      "|3\t|2.389158010482788\t|-4835.658203125\t|-1.7493785619735718\t|118.48883106470107\t|35.21237373352051\n",
      "|4\t|3.0184929370880127\t|-5121.23876953125\t|-2.847529172897339\t|186.43517192125321\t|46.461792125701905\n",
      "|5\t|3.634564161300659\t|-1891.24658203125\t|-2.9569671154022217\t|222.37692553043365\t|56.507850608825684\n",
      "|6\t|4.263267993927002\t|-2063.98291015625\t|-6.7474260330200195\t|491.57641653060915\t|62.972778511047366\n",
      "|7\t|4.8945698738098145\t|-602.8543090820312\t|-10.166610717773438\t|335.47835911273955\t|67.87132019042969\n",
      "|8\t|5.523971319198608\t|-1141.9130859375\t|-4.359653472900391\t|830.0047441673279\t|68.69735343933105\n",
      "|9\t|6.137554407119751\t|-892.8964233398438\t|-7.769405364990234\t|756.6080447387695\t|73.21599872589111\n",
      "|10\t|6.772531986236572\t|-4862.08447265625\t|-8.16441822052002\t|985.7788113212586\t|81.65736518859863\n",
      "|11\t|7.394241094589233\t|-2368.980712890625\t|-14.399822235107422\t|1484.435336151123\t|94.83865882873535\n",
      "|12\t|8.018978595733643\t|-6414.43994140625\t|-20.34050750732422\t|1042.2547317314147\t|100.49619190216065\n",
      "|13\t|8.643092632293701\t|-4565.458984375\t|-26.126493453979492\t|971.9997852897644\t|126.62465293884277\n",
      "|14\t|9.259349584579468\t|-3837.590576171875\t|-21.170907974243164\t|1717.8068163108826\t|121.62974601745606\n",
      "|15\t|9.903864622116089\t|-1222.6683349609375\t|-28.943374633789062\t|2476.0700759124757\t|139.6173104095459\n",
      "|16\t|10.532122611999512\t|-4739.84033203125\t|-21.549610137939453\t|2882.2408743286132\t|141.19751861572266\n",
      "|17\t|11.165343046188354\t|-1003.705810546875\t|-21.043481826782227\t|3638.096710510254\t|-4.098766632080078\n",
      "|18\t|11.78703260421753\t|-5771.8359375\t|-24.059673309326172\t|3535.79213142395\t|-413.82692077636716\n",
      "|19\t|12.416576862335205\t|-3607.229248046875\t|-28.96409797668457\t|4554.895865211487\t|-629.7714373779297\n",
      "|20\t|13.040909051895142\t|-1432.3446044921875\t|-17.735084533691406\t|4345.185928878785\t|-52.05159683227539\n",
      "|21\t|13.639680624008179\t|-3372.538818359375\t|-33.744144439697266\t|5436.181531829834\t|-125.30692611694336\n",
      "|22\t|14.239155292510986\t|-4291.27587890625\t|-21.644376754760742\t|3924.626321563721\t|-250.46024444580078\n",
      "|23\t|14.872835397720337\t|-655.37060546875\t|-38.53483581542969\t|6824.635153656006\t|-248.2704817199707\n",
      "|24\t|15.493772745132446\t|-4258.306640625\t|-28.431907653808594\t|5491.625012359619\t|-464.2796551513672\n",
      "|25\t|16.108513593673706\t|-6823.5244140625\t|-58.06672286987305\t|8359.856794586181\t|-599.552253112793\n",
      "|26\t|16.738830089569092\t|-637.0435180664062\t|-55.91265106201172\t|8849.47022491455\t|-661.3473550415039\n",
      "|27\t|17.365570306777954\t|-4715.884765625\t|-38.3221321105957\t|6180.054304084778\t|-54.73944030761719\n",
      "|28\t|17.958300828933716\t|-2073.683349609375\t|-39.5037956237793\t|6644.210455322265\t|-481.0782661437988\n",
      "|29\t|18.591482639312744\t|-253.5877685546875\t|-33.191078186035156\t|6945.928730430603\t|-451.59684829711915\n",
      "|30\t|19.210635900497437\t|-1112.01708984375\t|-33.08625030517578\t|7529.30107673645\t|96.5334001159668\n",
      "|31\t|19.84590244293213\t|-827.824462890625\t|-47.125091552734375\t|7862.797732391357\t|-173.82238555908202\n",
      "|32\t|20.463825225830078\t|-4903.3447265625\t|-69.93348693847656\t|5710.626478347778\t|-425.33562301635743\n",
      "|33\t|21.096051692962646\t|-1879.6298828125\t|-45.94869613647461\t|2717.4011840343474\t|-61.39324951171875\n",
      "|34\t|21.739462852478027\t|-1574.1351318359375\t|-64.96971893310547\t|6509.934454421997\t|-314.8603718566894\n",
      "|35\t|22.35503888130188\t|-3049.061279296875\t|-54.92888259887695\t|3887.593564834595\t|-86.57945266723632\n",
      "|36\t|22.974702835083008\t|-4394.7705078125\t|-56.7220573425293\t|3225.85084072113\t|-134.4960498046875\n",
      "|37\t|23.622355937957764\t|-5577.27392578125\t|-61.946319580078125\t|3460.442798233032\t|-53.63516876220703\n",
      "|38\t|24.24566888809204\t|-1337.7435302734375\t|-77.75410461425781\t|7644.985309448242\t|-6.119963989257813\n",
      "|39\t|24.911463737487793\t|-4217.89453125\t|-64.88560485839844\t|14570.835364379884\t|9.613896026611329\n",
      "|40\t|25.573505878448486\t|-3049.616455078125\t|-62.17787551879883\t|10711.902489700318\t|-297.5951385498047\n",
      "|41\t|26.243990182876587\t|-4783.27099609375\t|-65.86006927490234\t|11242.787345581055\t|-496.2708917236328\n",
      "|42\t|26.890995025634766\t|-381.25250244140625\t|-62.2532844543457\t|14196.290351028443\t|-502.4008447265625\n",
      "|43\t|27.541706323623657\t|-1828.896728515625\t|-75.16117858886719\t|9879.424535369873\t|-362.68684753417966\n",
      "|44\t|28.185118436813354\t|-3323.868408203125\t|-57.47829818725586\t|16215.033899841308\t|-166.64848083496094\n",
      "|45\t|28.839073181152344\t|-717.7604370117188\t|-63.64154052734375\t|11256.126528778077\t|-447.4943927001953\n",
      "|46\t|29.483213186264038\t|-1000.4707641601562\t|-61.52763748168945\t|14029.150339813232\t|-464.35318099975586\n",
      "|47\t|30.12769103050232\t|-1357.5125732421875\t|-95.11978149414062\t|12847.932989501953\t|-403.42958374023436\n",
      "|48\t|30.766154289245605\t|-733.7689819335938\t|-69.27710723876953\t|9637.17954093933\t|74.37566101074219\n",
      "|49\t|31.42219066619873\t|-3401.974609375\t|-95.05859375\t|6390.972050552368\t|35.14991149902344\n",
      "|50\t|32.032570123672485\t|-1319.9100341796875\t|-72.06452178955078\t|7887.843602600097\t|-219.2389532470703\n",
      "|51\t|32.63618087768555\t|-1015.5640869140625\t|-71.0223388671875\t|9249.41817970276\t|-426.55774993896483\n",
      "|52\t|33.24007487297058\t|-5226.71630859375\t|-83.32784271240234\t|7186.89020401001\t|-119.81121520996093\n",
      "|53\t|33.843841314315796\t|-1455.39501953125\t|-82.24098205566406\t|7570.7126422119145\t|-219.87787963867189\n",
      "|54\t|34.45213317871094\t|-6430.68505859375\t|-106.16455841064453\t|6882.771608428955\t|-594.3552255249024\n",
      "|55\t|35.082111120224\t|-747.3308715820312\t|-96.42082977294922\t|7457.938742218018\t|-334.34452850341796\n",
      "|56\t|35.75958609580994\t|-2706.832763671875\t|-100.18761444091797\t|7017.327330322266\t|-43.84729156494141\n",
      "|57\t|36.38847279548645\t|-1575.939453125\t|-107.06351470947266\t|4842.840124206543\t|13.02364356994629\n",
      "|58\t|37.048115968704224\t|-1425.6656494140625\t|-98.86260223388672\t|5524.7452341461185\t|-135.0384019470215\n",
      "|59\t|37.707568645477295\t|-2919.3583984375\t|-106.36618041992188\t|7433.5601014328\t|294.33553314208984\n",
      "|60\t|38.3347225189209\t|-2379.048828125\t|-96.89181518554688\t|7317.652354278564\t|92.26586624145507\n",
      "|61\t|38.97212290763855\t|-945.3330078125\t|-79.47337341308594\t|4153.003053741455\t|-132.8681266784668\n",
      "|62\t|39.61375594139099\t|-1136.0068359375\t|-85.14396667480469\t|7551.121537246704\t|427.24859100341797\n",
      "|63\t|40.28018283843994\t|-2759.20751953125\t|-103.26145935058594\t|8601.567674865722\t|-349.73491271972654\n",
      "|64\t|40.89546227455139\t|-4876.2216796875\t|-100.68576049804688\t|6943.896512680054\t|245.5310662841797\n",
      "|65\t|41.51644802093506\t|-7023.333984375\t|-93.84016418457031\t|5984.394179000855\t|443.8175184631348\n",
      "|66\t|42.140442848205566\t|-1989.0904541015625\t|-128.55323791503906\t|12980.874717712402\t|246.44071887969972\n",
      "|67\t|42.76054406166077\t|-233.87257385253906\t|-101.4078140258789\t|16260.177260742188\t|152.707434425354\n",
      "|68\t|43.38211941719055\t|-2815.10791015625\t|-103.28085327148438\t|10291.724206008912\t|207.4568892288208\n",
      "|69\t|43.99909973144531\t|-5053.029296875\t|-117.55803680419922\t|11658.619656066894\t|304.6147043609619\n",
      "|70\t|44.61007213592529\t|-637.7237548828125\t|-110.35698699951172\t|26343.142551879882\t|66.91686832427979\n",
      "|71\t|45.23357105255127\t|-3767.14208984375\t|-125.48625183105469\t|22118.156850433348\t|335.36317092895507\n",
      "|72\t|45.84808611869812\t|-2415.747314453125\t|-145.57398986816406\t|22940.018152465822\t|236.64226734161377\n",
      "|73\t|46.470412254333496\t|-4833.55322265625\t|-99.9674072265625\t|16876.007875976564\t|362.4267387390137\n",
      "|74\t|47.12495470046997\t|-1204.6453857421875\t|-155.7484130859375\t|29906.619133605956\t|634.4277741622925\n",
      "|75\t|47.801584243774414\t|-2831.25537109375\t|-130.19479370117188\t|33892.54943908691\t|145.73460256576539\n",
      "|76\t|48.49467658996582\t|-3176.509765625\t|-137.84288024902344\t|12552.83777481079\t|262.04545627593996\n",
      "|77\t|49.220399618148804\t|-2335.296630859375\t|-138.76649475097656\t|19268.17955001831\t|91.79678778648376\n",
      "|78\t|49.97787070274353\t|-3881.809326171875\t|-136.9498291015625\t|24760.449360351562\t|135.19914413452148\n",
      "|79\t|50.69006657600403\t|-1363.032470703125\t|-140.8874969482422\t|24894.46221343994\t|92.32345096588135\n",
      "|80\t|51.37776446342468\t|-673.1553344726562\t|-135.8374786376953\t|10171.99474029541\t|289.08128698349\n",
      "|81\t|52.112821102142334\t|-2068.6337890625\t|-136.3269500732422\t|8350.603427734375\t|279.2726298522949\n",
      "|82\t|52.84281778335571\t|-3780.48681640625\t|-131.4568328857422\t|10436.710003662109\t|63.037636280059814\n",
      "|83\t|53.57035183906555\t|-3492.204833984375\t|-140.99691772460938\t|7877.662726287842\t|36.5053409576416\n",
      "|84\t|54.32660460472107\t|-2071.92333984375\t|-134.78839111328125\t|7461.29491973877\t|631.9805318832398\n",
      "|85\t|55.10038185119629\t|-296.2102966308594\t|-149.3357391357422\t|8088.550771789551\t|333.4439368247986\n",
      "|86\t|55.84060454368591\t|-4042.0517578125\t|-134.6688232421875\t|4105.326149520874\t|192.8328091430664\n",
      "|87\t|56.59465527534485\t|-1915.17822265625\t|-167.18528747558594\t|6142.948603973388\t|175.45651432037354\n",
      "|88\t|57.26031470298767\t|-1568.83935546875\t|-130.63528442382812\t|8471.147296295167\t|338.45441497802733\n",
      "|89\t|57.90462374687195\t|-362.8280029296875\t|-135.44314575195312\t|5871.99256904602\t|881.8078704833985\n",
      "|90\t|58.63326406478882\t|-770.184814453125\t|-148.27096557617188\t|6190.0300567626955\t|395.04646446228026\n",
      "|91\t|59.354533672332764\t|-6940.85791015625\t|-163.77752685546875\t|7144.20903503418\t|213.17137397766112\n",
      "|92\t|60.091126918792725\t|-4176.78857421875\t|-157.9473876953125\t|9754.851814727783\t|607.7735197067261\n",
      "|93\t|60.822715044021606\t|-1271.3790283203125\t|-159.09768676757812\t|6540.240337524414\t|391.1468503761291\n",
      "|94\t|61.548948764801025\t|-2968.645263671875\t|-171.14744567871094\t|4541.503730735779\t|455.4657738304138\n",
      "|95\t|62.246259450912476\t|-233.7373504638672\t|-166.77113342285156\t|5639.914599304199\t|471.1569023513794\n",
      "|96\t|62.90893507003784\t|-1170.34130859375\t|-132.46484375\t|7771.680971527099\t|639.8172320938111\n",
      "|97\t|63.63288426399231\t|-3014.029052734375\t|-163.14601135253906\t|6834.592108078003\t|327.95052667617796\n",
      "|98\t|64.3227128982544\t|-1805.749755859375\t|-154.180908203125\t|3749.8197749328615\t|274.7282521057129\n",
      "|99\t|64.99635648727417\t|-1442.3887939453125\t|-162.11624145507812\t|4754.126570587158\t|209.66564861297607\n",
      "|100\t|65.65078854560852\t|-1602.5067138671875\t|-156.3233642578125\t|3818.8564778137206\t|318.3739051437378\n",
      "|101\t|66.33856868743896\t|-3299.075439453125\t|-146.1346893310547\t|5190.880129165649\t|784.2093013763428\n",
      "|102\t|67.07919311523438\t|-1156.369384765625\t|-141.3654022216797\t|5169.88183517456\t|404.07087997436525\n",
      "|103\t|67.82911944389343\t|-3730.968017578125\t|-147.73150634765625\t|2282.8711891174316\t|316.0876547431946\n",
      "|104\t|68.56028771400452\t|-450.58154296875\t|-160.76800537109375\t|2526.4716943359376\t|280.2314569282532\n",
      "|105\t|69.29864764213562\t|-1554.0556640625\t|-144.7398681640625\t|4233.313776550293\t|192.14746097564696\n",
      "|106\t|70.02615714073181\t|-1954.3289794921875\t|-160.72886657714844\t|2435.2095432281494\t|606.0923461151123\n",
      "|107\t|70.75126457214355\t|-604.3557739257812\t|-160.44261169433594\t|3978.6209692382813\t|721.898254776001\n",
      "|108\t|71.48809576034546\t|-3036.9892578125\t|-153.9756622314453\t|3146.6696579742434\t|251.18533977508545\n",
      "|109\t|72.26394844055176\t|-504.2681884765625\t|-154.14111328125\t|1763.7423010253906\t|375.4804035949707\n",
      "|110\t|72.99022793769836\t|-1285.6927490234375\t|-158.29974365234375\t|1380.578545074463\t|113.14980234146118\n",
      "|111\t|73.72870945930481\t|-4144.544921875\t|-166.40399169921875\t|2872.164147567749\t|-59.08787046432495\n",
      "|112\t|74.4879240989685\t|-6394.7568359375\t|-148.68995666503906\t|3969.972544708252\t|256.74018018722535\n",
      "|113\t|75.24836349487305\t|-1491.7236328125\t|-190.77569580078125\t|15891.696772155761\t|247.33225124359132\n",
      "|114\t|75.99833393096924\t|-1706.38330078125\t|-170.97528076171875\t|14129.866266479492\t|140.59655780792235\n",
      "|115\t|76.69597339630127\t|-3022.382568359375\t|-179.65103149414062\t|10921.03308517456\t|163.1702537536621\n",
      "|116\t|77.49277830123901\t|-1252.3629150390625\t|-168.2317657470703\t|8555.655181655884\t|168.74405550956726\n",
      "|117\t|78.14280223846436\t|-1108.3623046875\t|-153.76536560058594\t|19475.56523284912\t|949.795192489624\n",
      "|118\t|78.86297369003296\t|-2247.691162109375\t|-179.29788208007812\t|12264.502952880859\t|612.3826840209961\n",
      "|119\t|79.57088232040405\t|-3237.2490234375\t|-183.7077178955078\t|13144.811990356446\t|389.41422527313233\n",
      "|120\t|80.28252935409546\t|-4298.517578125\t|-207.09951782226562\t|15220.80922668457\t|592.6927139282227\n",
      "|121\t|80.99583601951599\t|-2989.174072265625\t|-183.57273864746094\t|12991.11393737793\t|556.9698187637329\n",
      "|122\t|81.72414755821228\t|-1075.422119140625\t|-178.00833129882812\t|10107.045278930664\t|299.61184295654294\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43msenv\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ETH_Code/SemProj/SetBasedRL/examples/../SBML/SBRL/actorcitic.py:112\u001b[0m, in \u001b[0;36mActorCritic.train\u001b[0;34m(self, env, episodes, verbose)\u001b[0m\n\u001b[1;32m    109\u001b[0m num_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer\u001b[38;5;241m.\u001b[39mfull \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer\u001b[38;5;241m.\u001b[39mindx \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m--> 112\u001b[0m     critic_loss, actor_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m     total_actor_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m actor_loss\n\u001b[1;32m    114\u001b[0m     total_critic_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m critic_loss\n",
      "File \u001b[0;32m~/ETH_Code/SemProj/SetBasedRL/examples/../SBML/SBRL/algorithms/ddpg.py:99\u001b[0m, in \u001b[0;36mDDPG.train_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaN in target Q values.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     97\u001b[0m     target \u001b[38;5;241m=\u001b[39m rewards \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgamma\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m target_q \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m dones)\n\u001b[0;32m---> 99\u001b[0m critic_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_critic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstates\u001b[49m\u001b[43m,\u001b[49m\u001b[43mactions\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactor_train_mode\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mset\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    102\u001b[0m     z_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maugmentState(states)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/ETH_Code/SemProj/SetBasedRL/examples/../SBML/SBRL/actorcitic.py:135\u001b[0m, in \u001b[0;36mActorCritic.train_critic\u001b[0;34m(self, state, action, target)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid critic training mode\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 135\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic_optim\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/ETH_Code/SemProj/SetBasedRL/.venv/lib/python3.12/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ETH_Code/SemProj/SetBasedRL/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ETH_Code/SemProj/SetBasedRL/.venv/lib/python3.12/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "agent.train(senv,1000,True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
